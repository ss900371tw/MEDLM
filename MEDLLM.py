import streamlit as st
from PIL import Image
import google.generativeai as genai
import os
from dotenv import load_dotenv
import streamlit.components.v1 as components
from streamlit_chat import message
# è®€å– API é‡‘é‘°
load_dotenv()
GOOGLE_API_KEY = 'AIzaSyBgMdKfVDl7MO-bE3IY2EnLc_1t7pWkoUw'



# åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ–‡å­—æ¨¡å‹èˆ‡å½±åƒæ¨¡å‹åˆ†é–‹ï¼‰
text_model = genai.GenerativeModel("gemini-2.5-flash")
vision_model = genai.GenerativeModel("gemini-2.5-pro")
chat = text_model.start_chat()


# === Session state åˆå§‹åŒ– ===
if "messages" not in st.session_state:
    st.session_state.messages = []
if "pending_images" not in st.session_state:
    st.session_state.pending_images = []

# === é é¢èˆ‡æ¨£å¼è¨­å®š ===
st.set_page_config(page_title="AI é†«ç™‚å•è¨ºèˆ‡å½±åƒåŠ©ç†", page_icon="ğŸ’Š")
st.markdown("""
    <style>
    .element-container:has(.chat-message) {
        padding: 4px 16px;
    }
    .stChatMessage {
        max-width: 90%;
    }
    </style>
""", unsafe_allow_html=True)
st.title("ğŸ’Š å°ç£ AI é†«ç™‚å•è¨ºèˆ‡å½±åƒåŠ©ç†")

# === ä¸Šå‚³åœ–ç‰‡å€ ===
uploaded_images = st.file_uploader("ğŸ“ ä¸Šå‚³é†«å­¸å½±åƒï¼ˆå¯å¤šå¼µï¼‰", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

if uploaded_images:
    st.session_state.pending_images = uploaded_images

# === é¡¯ç¤ºæ­·å²è¨Šæ¯ ===
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg.get("images"):
            for img in msg["images"]:
                st.image(img, use_column_width=True)

# === è¼¸å…¥æ¬„ï¼šå›ºå®šåœ¨åº•éƒ¨ ===
user_input = st.chat_input("è«‹è¼¸å…¥ç—‡ç‹€æè¿°ï¼Œå¯æ­é…åœ–ç‰‡")

# === Gemini å›æ‡‰é‚è¼¯ ===
if user_input or st.session_state.pending_images:
    # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    st.chat_message("user").markdown(user_input or "ï¼ˆåƒ…é™„åœ–ï¼‰")
    if st.session_state.pending_images:
        for img in st.session_state.pending_images:
            st.image(img, use_column_width=True)

    # å„²å­˜ä½¿ç”¨è€…è¨Šæ¯
    st.session_state.messages.append({
        "role": "user",
        "content": user_input or "ï¼ˆåƒ…é™„åœ–ï¼‰",
        "images": st.session_state.pending_images
    })

    # Gemini åˆ†æ
    full_reply = ""
    try:
        if st.session_state.pending_images:
            for idx, img_file in enumerate(st.session_state.pending_images):
                img = Image.open(img_file)
                prompt = f"""
ä½ æ˜¯ä¸€ä½å°ç£çš„å°ˆæ¥­é†«ç™‚å½±åƒè¨ºæ–· AI åŠ©ç†ï¼Œè«‹åˆ¤è®€ç¬¬ {idx+1} å¼µé†«å­¸å½±åƒçš„ç•°å¸¸æƒ…æ³ï¼Œ
æ¨æ¸¬å¯èƒ½çš„ç—…ç¶æˆ–ç–¾ç—…ï¼ˆå¦‚è‚ºç‚ã€è…«ç˜¤ã€éª¨æŠ˜ç­‰ï¼‰ï¼Œä¸¦çµåˆç—‡ç‹€æè¿°åˆ†æã€‚
ç¦æ­¢ä½¿ç”¨ç°¡é«”èˆ‡ã€Œåƒ…ä¾›åƒè€ƒã€ç­‰èªå¥ã€‚
ç—‡ç‹€æè¿°ï¼š{user_input if user_input else "ï¼ˆç„¡è¼¸å…¥ï¼‰"}
""".strip()
                result = vision_model.generate_content([prompt, img])
                full_reply += f"ğŸ“· ç¬¬ {idx+1} å¼µåœ–ç‰‡åˆ¤è®€çµæœï¼š\n{result.text}\n\n"
        else:
            prompt = f"""
ä½ æ˜¯å°ç£çš„å°ˆæ¥­é†«ç™‚å•è¨º AI åŠ©ç†ï¼Œè«‹æ ¹æ“šä¸‹åˆ—ç—‡ç‹€æè¿°ï¼Œæä¾›å¯èƒ½ç–¾ç—…ã€å»ºè­°æª¢æŸ¥èˆ‡è™•ç½®æ–¹å¼ã€‚
è«‹ç”¨æ­£é«”ä¸­æ–‡å›è¦†ï¼Œä¸ä½¿ç”¨ç°¡é«”å­—æˆ–ã€Œåƒ…ä¾›åƒè€ƒã€ã€‚
ç—‡ç‹€æè¿°ï¼š{user_input}
"""
            result = text_model.generate_content(prompt)
            full_reply = result.text

    except Exception as e:
        full_reply = f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"

    # é¡¯ç¤ºåŠ©ç†å›è¦†
    with st.chat_message("assistant"):
        st.markdown(full_reply)

    # å„²å­˜åŠ©ç†è¨Šæ¯
    st.session_state.messages.append({
        "role": "assistant",
        "content": full_reply,
        "images": None
    })

    # æ¸…ç©ºæš«å­˜åœ–ç‰‡
    st.session_state.pending_images = []
